\documentclass[paper = a4]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[autostyle = true, german = quotes]{csquotes} % Anführungszeichen

\usepackage{amsmath}
\usepackage{graphicx}

\begin{document}

\subject{Praktikum Multicore"=Programmierung}
\title{Protokoll zu Projekt~6: Mehrgittermethoden}
\author{Florian Klemme \and Manuel Leßmann}
\maketitle

\section{Jakobi- und Gauß-Seidel-Verfahren}

\begin{quote}
    a) Programmieren Sie eine serielle Version des Jakobi"=Verfahrens. Gegeben sei dazu [\dots] \(f(x, y) = 32(x(1 - x) + y(1 - y))\). Beachten Sie dabei auch die Randbedingungen [\(u(x, y) = 0 \quad \forall (x, y) \in \Gamma\)]. Verwenden Sie zur Überprüfung Ihres Programms auf Korrektheit die analytische Lösung \(u(x, y) = 16x(1 - x)y(1 - y) \quad \forall (x, y) \in \Omega\).
\end{quote}

Gemacht. Implementierung scheint auch korrekt zu sein, da nur eine minimale Abweichung zur analytischen Lösung besteht. Ansonsten gibt's hier nichts zu zeigen/schreiben. Kann wohl am Ende hier im Protokoll entfallen.

\begin{quote}
    b) Implementieren Sie ebenfalls eine serielle Version des Gauß"=Seidel"=Verfahrens. Vergleichen Sie die gewonnenen Ergebnisse mit den Ergebnissen des Jakobi"=Verfahrens. Was fällt beim Vergleich der Iterationsschrittzahlen sowie der Laufzeiten beider Verfahren über verschiedenen Verfeinerungen (\(h = \frac{1}{2^l} \text{ mit } l = 1, 2, \dots, 6, \dots\)) auf?
\end{quote}

Der Unterschied zu Jakobi in der (sequenziellen) Implementierung ist marginal, daher habe ich sie kurzerhand hinzugefügt. Messungen habe ich noch keine angestellt.

Hier ist bestimmt \(h = \frac{1}{2^{l} + 1}\) gemeint. Zumindest macht diese Unterteilung später im Mehrgitter"=Verfahren Sinn, da \(h = \frac{1}{2}\) \emph{linker Rand -- Punkt -- rechter Rand} bedeutet, also ein Grid mit nur einem Punkt. (ungerade, schlecht halbierbar)

\begin{quote}
    c) Messen Sie mit Hilfe der in a) angegebenen analytischen Lösung für beide Verfahren den maximalen Approximationsfehler mit Hilfe der euklidischen Norm in jedem Iterationsschritt und für ein gewähltes h und stellen Sie diesen graphisch dar.
\end{quote}

Euklidische Norm bedeutet hier wohl: einfacher Abstand. Noch nicht implementiert.

\begin{quote}
    d) Da hier innerhalb eines einzelnen Iterationsschritts keine Datenabhängigkeiten zu finden sind, lässt sich das Jakobi"=Verfahren durch einfaches Aufteilen der Berechnungen auf verscheidene Prozessoren und Kommunizieren eventueller Überlappungen parallelisieren. Entwerfen Sie eine parallele Version des Verfahrens (wahlweise mit OpenMP oder Cuda/OpenCL) und verifizieren Sie Ihre Ergebnisse gegenüber der seriellen Variante.
\end{quote}

OpenMP Variante läuft, wenn auch noch recht langsam. Ergebnisse stimmen soweit. GPU Beschleunigung hat hier so viel Potenzial, dass man es eigentlich nicht nicht implementieren kann.

\begin{quote}
    e) Im Gegensatz zum Jakobi"=Verfahren zeigt das Gauß"=Seidel"=Verfahren Datenabhängigkeiten innerhalb der einzelnen Iterationsschritte. Daher eignet sich eine naive Herangehensweise nicht, um dieses Verfahren ausreichend zu parallelisieren. Ihre Aufgabe ist es, eine sinnvolle Methodik zu entwickeln, mit welcher sich dieses Verfahren parallelisieren lässt.
\end{quote}

Ich habe ein Verfahren implementiert, dass zumindest so viele Kerne nutzen kann, wie der Vektor lang ist. Für CPU"=Beschleunigung sollte das okay sein. Es gibt aber augenscheinlich auch noch andere Ansätze mit Graphfärbung, usw. Ich habe noch eine Skizze \ref{fig:gaussseidelskizze} angehängt, die bei der Beschreibung des Verfahrens später ein nützliche Gedankenstütze sein könnte.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{gaussseidelskizze}
    \caption{Skizze zum Entwurfsgedanken zu Gauß"=Seidel, parallel.}
    \label{fig:gaussseidelskizze}
\end{figure}

Mir ist noch eine Verbesserungsidee gekommen, die die Auslastung der Threads bei großen Grid verbessern könnte. Die Skizze \ref{fig:gaussseideldreiecke} stellt die Überlegung dar. Noch nicht implementiert.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{gaussseideldreiecke}
    \caption{Verbesserung der Threadauslastung, Gauß"=Seidel, parallel.}
    \label{fig:gaussseideldreiecke}
\end{figure}

Im Gegensatz zum Jakobi"=Verfahren sollte hier das GPU"=Potenzial geringer ausfallen.

\begin{quote}
    f) Ermitteln Sie den Speedup für verschiedene Problemgrößen für beide Verfahren (\(h = \frac{1}{2^l} \text{ mit } l = 1, 2, \dots, 6, \dots\)). Beurteilen Sie damit auch die Qualität ihrer Parallelisierungen.
\end{quote}

Joa, hier ist wohl noch was zu tun.


\section{Mehrgitter-Verfahren}

\subsection*{a)}
Ein grobes Gitter führt zwangsläufig zu Undersampling. Gerade bei hochfrequenten Funktionen entstehen dadurch schwerwiegende Aliasingeffekte, die sich auch durch die Ausführung von Gauss-Seidel nicht verringern lassen, da die Informationen schlicht im Startvektor nicht enthalten sind. Deshalb sollte man zunächst auf feineren Gittern iterieren. Dadurch erstellt man einen Startvektor, der zwar dieselbe Feinheit hat, jedoch auch Informationen aus den hochfrequenten Teilen der Funktionen beinhaltet. Dieses Verfahren führt zur Glättung des Fehlers, der zwangsläufig durch Aliasing entsteht.

\subsection*{b)}
%\begin{table}[h]
\begin{tabular}{l|l|l|l|l}
\hline
z1 & z2 & Time   & Mean Error & Max Error\\
\hline
4  & 4  & 0,0599 & 0,0324     & 0,0880   \\
4  & 8  & 0,0634 & 0,0321     & 0,0877   \\
4  & 16 & 0,0715 & 0,0314     & 0,0871   \\
4  & 32 & 0,0876 & 0,0305     & 0,0859   \\
8  & 4  & 0,0634 & 0,0323     & 0,0877   \\
8  & 8  & 0,0674 & 0,0320     & 0,0874   \\
8  & 16 & 0,0755 & 0,0313     & 0,0868   \\
8  & 32 & 0,0946 & 0,0304     & 0,0856   \\
16 & 4  & 0,0714 & 0,0321     & 0,0871   \\
16 & 8  & 0,0755 & 0,0317     & 0,0868   \\
16 & 16 & 0,0835 & 0,0311     & 0,0862   \\
16 & 32 & 0,0997 & 0,0302     & 0,0850   \\
32 & 4  & 0,0876 & 0,0317     & 0,0859   \\
32 & 8  & 0,0916 & 0,0313     & 0,0857   \\
32 & 16 & 0,0997 & 0,0307     & 0,0851   \\
32 & 32 & 0,1159 & 0,0298     & 0,0839   \\
\hline
\end{tabular}
%\end{table}
n=256, hMax=h*4, alpha=1\\

%\par\medskip
Offensichtlich hängt der Fehler nur wenig von z2 und fast gar nicht von z1 ab.

\subsection*{c)}
\begin{tabular}{l|l|l|l}
\hline
n    & alpha & Mean Error & Max Error \\
\hline
256  & 1     & 0,0771     & 0,1962 \\
256  & 2     & 0,0771     & 0,1962 \\
512  & 1     & 0,0431     & 0,1052 \\
512  & 2     & 0,0431     & 0,1053 \\
1024 & 1     & 0,0321     & 0,0853 \\
1024 & 2     & 0,0222     & 0,0548 \\
2048 & 1     & 0,2341     & 0,5783 \\
2048 & 2     & 0,0111     & 0,0289 \\
\hline
\end{tabular}
z1=4, z2=4, hMax = 16*h\\

Ein höherer Alpha-Wert führt besonders bei großer Gitterfeinheit und wenig Iterationen von Gauss-Seidel zu deutlich geringeren Fehlern.

\subsection*{e)}
//TODO Tabelle mit n/time/speedup/efficiency für ein hMaxFactor, alpha=2

\subsection*{f)}
//TODO Tabelle mit verfahren/time/speedup/error für n=2048

\end{document}
